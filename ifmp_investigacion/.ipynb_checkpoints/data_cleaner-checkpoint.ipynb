{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3457ea62-4589-475f-90d2-54d9286a3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug  1 10:43:34 2021\n",
    "\n",
    "@author: IgVinçon\n",
    "\"\"\"\n",
    "\n",
    "############################ IMPORT LIBRARIES ################################\n",
    "import unicodedata\n",
    "import json\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "############################# SUB-ROUTINES ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41cf3b9-2f7b-451e-9feb-669866bd6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### CLEANING DATAFRAMES ##############################\n",
    "# Open the data, if it's not already in memory.\n",
    "anii_df = pd.read_csv('anii_corregido.csv', index_col = 0, na_values = 'n/a')\n",
    "csic_df = pd.read_csv('csic.csv', index_col = 0, na_values = 'n/a')\n",
    "ei_df = pd.read_csv('ei.csv', index_col = 0, na_values = 'n/a')\n",
    "sni_df = pd.read_csv('sni.csv', index_col = 0, na_values = 'n/a')\n",
    "# Open manually compiled data and data with researchers' names (includes alts.)\n",
    "manual_df = pd.read_excel('manual.xlsx', na_values = 'n/a')\n",
    "researchers_df = pd.read_excel('docentes_ifymp.xlsx', na_values = 'n/a')\n",
    "\n",
    "############################# ANII DATAFRAME ##################################\n",
    "#anii_df['anio'] = anii_df['codigo'].replace({'(.*)((?<=\\_)\\d{4}(?=\\_))(.*)': '\\\\2'}, regex = True)\n",
    "#anii_df.to_csv('anii_corregido.csv')\n",
    "\n",
    "# The column \"beneficiario\" has both the institution and the name of the\n",
    "# reponsible person for the project. Thus that information must be separated.\n",
    "anii_df['institucion'] = (\n",
    "    anii_df['beneficiario'].replace(r'^.*\\:', '', regex = True).str.strip()\n",
    ")\n",
    "anii_df['beneficiario'] = (\n",
    "    anii_df['beneficiario'].replace(r'\\:.*$', '', regex = True).str.strip()\n",
    ")\n",
    "anii_df = anii_df.replace(r'^\\s*$', np.nan, regex = True)\n",
    "\n",
    "# Calculate the finishing date for each project:\n",
    "# Replace non date values with missing values.\n",
    "anii_df['fecha de inicio'] = (\n",
    "    anii_df['fecha de inicio'].replace('00.00.0000', np.nan)\n",
    ")\n",
    "# Convert 'fecha de inicio' to datetime format\n",
    "anii_df['fecha de inicio'] = (\n",
    "    pd.to_datetime(anii_df['fecha de inicio'], format = '%d.%m.%Y')\n",
    ")\n",
    "# Assign a variable to store the data in 'duracion' as integers\n",
    "anii_df['offset'] = (\n",
    "    pd.to_numeric(anii_df['duracion']\n",
    "                  .replace(r'\\s\\w*$', '', regex = True).str.strip(),\n",
    "                  errors = 'coerce').fillna(0).astype('Int8')\n",
    ")\n",
    "# Create 'fecha fin' column that adds 'fecha de inicio' and 'offset'\n",
    "anii_df['fecha fin'] = (\n",
    "    anii_df.apply(\n",
    "        lambda x: x['fecha de inicio'] + pd.DateOffset(months = x['offset']),\n",
    "        axis = 1\n",
    "    )\n",
    ")\n",
    "anii_df = anii_df.drop(columns = 'offset')\n",
    "# Clean the 'responsable' column of multiple whitespaces.\n",
    "anii_df['beneficiario'] = (\n",
    "    anii_df['beneficiario'].str.replace(' +', ' ', regex = False)\n",
    ")\n",
    "\n",
    "anii_df['beneficiario'] = anii_df['beneficiario'].str.split(',')\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "anii_df['anio'] = anii_df['anio'].astype('float').astype('Int32')\n",
    "\n",
    "############################# SNI DATAFRAME ##################################\n",
    "# The 'name' columns is in Last Name , First Name format. In order to join the\n",
    "# datasets it should be in First Name Last Name (or Full Name) format.\n",
    "sni_df['nombres'] = (\n",
    "    sni_df['nombre'].replace(r'^.*\\,', '', regex = True).str.strip() # limpiar con unicode data (tildes)\n",
    ")\n",
    "sni_df['nombres'] = sni_df['nombres'].str.replace(' +', ' ', regex = False)\n",
    "sni_df['apellidos'] = (\n",
    "    sni_df['nombre'].replace(r'\\,.*$', '', regex = True).str.strip()\n",
    ")\n",
    "sni_df['apellidos'] = sni_df['apellidos'].str.replace(' +', ' ', regex = False)\n",
    "sni_df['nombre'] = sni_df['nombres'] + ' ' + sni_df['apellidos']\n",
    "\n",
    "############################## EI DATAFRAME ###################################\n",
    "# Create 'fecha de inicio' and 'fecha fin' from 'periodo'. Then convert them\n",
    "# to datetime format.\n",
    "ei_df['fecha de inicio'] = (\n",
    "    ei_df['periodo'].replace(r'\\-\\s.*$', '', regex = True).str.strip()\n",
    ")\n",
    "ei_df['fecha fin'] = (\n",
    "    ei_df['periodo'].replace(r'^.*\\s\\-', '', regex = True).str.strip()\n",
    ")\n",
    "ei_df['fecha de inicio'] = (\n",
    "    pd.to_datetime(ei_df['fecha de inicio'], format = '%Y-%m-%d')\n",
    ")\n",
    "ei_df['fecha fin'] = pd.to_datetime(ei_df['fecha fin'], format = '%Y-%m-%d')\n",
    "# Extract year from 'convocatoria' and thus create the column 'anio'.\n",
    "ei_df['anio'] = (\n",
    "    ei_df['convocatoria'].replace(r'^\\D*|\\s\\(.*\\)$|\\s\\-\\s.*$',\n",
    "                                  '', regex = True).str.strip()\n",
    ")\n",
    "# Clean 'convocatoria' from having each row start with the word 'convocatoria'\n",
    "# (thus avoiding redundancy).\n",
    "ei_df['convocatoria'] = (\n",
    "    ei_df['convocatoria']\n",
    "    .replace(r'^convocatoria\\s\\-\\s|^convocatoria\\sal|^convocatoria\\s',\n",
    "             '', regex = True).str.strip()\n",
    ")\n",
    "# Create column 'enlace' to contain, as a list, 'url_grupo' and 'url_convo'.\n",
    "ei_df['enlace'] = ei_df[['url_grupo', 'url_convo']].values.tolist()\n",
    "# If dataset was opened (and not in working memory) it may be necessary to\n",
    "# convert 'responsables' to list (from string) for later use in .explode\n",
    "#isna = ei_df['responsables'].isna()\n",
    "#ei_df.loc[isna, 'responsables'] = pd.Series([[]] * isna.sum()).values\n",
    "ei_df['responsables'] = ei_df['responsables'].fillna('[]')\n",
    "ei_df['responsables'] = ei_df['responsables'].apply(literal_eval)\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "ei_df['anio'] = ei_df['anio'].astype('float').astype('Int32')\n",
    "# Correct mistakes in some values (e.g.: \"vazquez\" should be \"vasquez\").\n",
    "to_repl = (\n",
    "    ei_df[ei_df['grupo'].str.contains('cicea', na = False)].index.to_list()\n",
    ")\n",
    "for i in range(len(to_repl)):\n",
    "    ei_df['responsables'].iloc[to_repl[i]].remove('alejandro vazquez')\n",
    "    ei_df['responsables'].iloc[to_repl[i]].extend(['alejandro vasquez'])\n",
    "    \n",
    "to_repl = (\n",
    "    ei_df[ei_df['grupo'].str.contains('cicada', na = False)].index.to_list()\n",
    ")\n",
    "ei_df['responsables'].iloc[to_repl[0]].extend(['alvaro cabana fajardo'])\n",
    "\n",
    "############################ CSIC DATAFRAME ###################################\n",
    "# If dataset was opened (and not in working memory) it may be necessary to\n",
    "# convert 'responsables' to list (from string) for later use in .explode\n",
    "#isna = csic_df['responsables'].isna()\n",
    "#csic_df.loc[isna, 'responsables'] = pd.Series([[]] * isna.sum()).values\n",
    "csic_df['responsables'] = csic_df['responsables'].fillna('[]')\n",
    "csic_df['responsables'] = csic_df['responsables'].apply(literal_eval)\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "csic_df['ano'] = csic_df['ano'].astype('float').astype('Int32')\n",
    "\n",
    "############################ MANUAL DATAFRAME ###################################\n",
    "manual_df['responsables'] = manual_df['responsables'].apply(literal_eval)\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "manual_df['anio'] = manual_df['anio'].astype('float').astype('Int32')\n",
    "\n",
    "############################ RESEARCHERS DF ###################################\n",
    "# Normalize data in the columns.\n",
    "for col in researchers_df.columns[:-2]:\n",
    "    researchers_df[col] = (researchers_df[col]\n",
    "                           .str.lower()\n",
    "                           .str.normalize('NFKD')   \n",
    "                           .str.encode('ascii', 'ignore')\n",
    "                           .str.decode('utf8')\n",
    "                           .str.strip())\n",
    "\n",
    "# Replace common names, that can be matched erronously, with NaN.\n",
    "to_repl = ['diego gonzalez', # antes estaba \"gonzalez garcia\"\n",
    "           'cecilia gomez', # problema empty string, debería estar solucionado\n",
    "           'ignacio rodriguez', # antes estaba \"monica da silva\"\n",
    "           'nicolas lopez', # empty string, debería estar solucionado\n",
    "           'monica perez',\n",
    "           'juan rodriguez',\n",
    "           'sebastian morales',\n",
    "           'daniel perez'] # agregado \"daniel perez\", situación empty string\n",
    "researchers_df = researchers_df.replace(to_repl, np.nan)\n",
    "\n",
    "# Create a Regex list out of the columns in 'cols' in order to have matches\n",
    "# when merging dataframes. This will account for name variations, for example,\n",
    "# it would match 'alejandro maiche' and 'alejandro maiche marini'.\n",
    "cols = [c for c in researchers_df.columns[5:-2]]    \n",
    "researchers_df = researchers_df.fillna('')\n",
    "to_repl = []\n",
    "for idx, row in researchers_df[cols].iterrows():\n",
    "    tmp = row.to_list()\n",
    "    tmp[:] = [x for x in tmp if x]\n",
    "    to_repl.append('|'.join(tmp))\n",
    "# Create a new column with the Regex, replace the empty strings with NaN and\n",
    "# clean the DF of NaN (those that don't have any name variation, e.g.: 'cecilia\n",
    "# gomez'). Thus avoiding matching with empty strings when \"merging\".\n",
    "researchers_df['regex'] = to_repl\n",
    "researchers_df = researchers_df.replace('', np.nan)\n",
    "researchers_df = researchers_df.dropna(how = 'all', subset = cols)\n",
    "to_repl = researchers_df['regex'].to_list()\n",
    "vals = researchers_df['id'].to_list()\n",
    "# Drop columns that are not needed in the merge\n",
    "cols.extend(['grado', 'primer nombre', 'segundo nombre', \n",
    "            'primer apellido', 'segundo apellido', 'regex'])\n",
    "researchers_df = researchers_df.drop(columns = cols)\n",
    "\n",
    "########################## REARRANGING COLUMNS ################################\n",
    "# Rename and rearrange columns order.\n",
    "anii_df = anii_df.rename(\n",
    "    columns = {'beneficiario': 'responsables',\n",
    "               'instrumento': 'convocatoria',\n",
    "               'codigo': 'id',\n",
    "               'fase_estado': 'fase estado anii',\n",
    "               'subsidio': 'monto',\n",
    "               'proyecto': 'nombre de proyecto / grupo',\n",
    "               'institucion': 'instituciones',\n",
    "               'area': 'area anii',\n",
    "               'sector': 'area'\n",
    "              }\n",
    ")\n",
    "cols = ['id', 'responsables', 'instituciones', 'convocatoria', 'anio',\n",
    "        'fecha de inicio', 'fecha fin', 'duracion', 'area', 'monto']\n",
    "anii_df = anii_df[cols + [c for c in anii_df.columns if c not in cols]]\n",
    "\n",
    "csic_df = csic_df.rename(\n",
    "    columns = {'ano': 'anio',\n",
    "               'monto total': 'monto',\n",
    "               'proyecto': 'nombre de proyecto / grupo',\n",
    "               'programa': 'convocatoria',\n",
    "               'area proyecto': 'area'}\n",
    ")\n",
    "cols = ['responsables', 'convocatoria', 'anio', 'monto']\n",
    "csic_df = csic_df[cols + [c for c in csic_df.columns if c not in cols]]\n",
    "\n",
    "ei_df = ei_df.rename(\n",
    "    columns = {'servicios involucrados': 'instituciones',\n",
    "               'grupo': 'nombre de proyecto / grupo'}\n",
    ")\n",
    "cols = ['responsables', 'instituciones', 'convocatoria', 'anio',\n",
    "        'fecha de inicio', 'fecha fin', 'periodo']\n",
    "ei_df = ei_df[cols + [c for c in ei_df.columns if c not in cols]]\n",
    "\n",
    "sni_df = sni_df.rename(columns = {'nombre': 'nombre completo'})\n",
    "cols = ['nombre completo', 'nombres', 'apellidos', 'nivel']\n",
    "sni_df = sni_df[cols + [c for c in sni_df.columns if c not in cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34c49c3-6298-40a2-b82a-af402c539bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## PROJECTS MERGING ################################\n",
    "# Add a column to identify the founding party once the DFs are joined\n",
    "anii_df['institucion financiadora'] = 'anii'\n",
    "csic_df['institucion financiadora'] = 'csic'\n",
    "ei_df['institucion financiadora'] = 'ei'\n",
    "for col in ['fase estado anii', 'area anii']:\n",
    "    ei_df[col] = np.nan\n",
    "    csic_df[col] = np.nan\n",
    "\n",
    "cols =  ['responsables',\n",
    "         'instituciones',\n",
    "         'institucion financiadora',\n",
    "         'convocatoria',\n",
    "         'anio',\n",
    "         'fecha de inicio',\n",
    "         'fecha fin',\n",
    "         'area',\n",
    "         'monto',\n",
    "         'nombre de proyecto / grupo',\n",
    "         'enlace',\n",
    "         'fase estado anii',\n",
    "         'area anii'] # agregar id anii? y dpto anii?\n",
    "\n",
    "# Drop columns that will not be used in joined DF.\n",
    "for df in [anii_df, csic_df, ei_df]:\n",
    "    df.drop(columns = [c for c in df.columns if c not in cols], inplace = True)\n",
    "# Concat DFs, one with all the projects, another with research only projects.\n",
    "projects_df  = pd.DataFrame(columns = cols)\n",
    "#research_df = pd.DataFrame(columns = cols)\n",
    "projects_df = pd.concat([anii_df, csic_df, ei_df, manual_df], ignore_index = True)\n",
    "#research_df = pd.concat([anii_df[anii_df['area anii'] == 'investigacion'],\n",
    " #                        csic_df, ei_df, manual_df], ignore_index = True)\n",
    "\n",
    "# Final \"merge\" that identifies researchers from IFyMP and assigns them an ID. <<<<<<<<<<<<<<<<<<<<< revisar\n",
    "projects_df = (\n",
    "    projects_df[projects_df['responsables'].notna()]\n",
    "    .explode('responsables', True)\n",
    ")\n",
    "projects_df['id'] = projects_df['responsables'].replace(to_repl, vals,\n",
    "                                                        regex = True)\n",
    "projects_df['id'] = projects_df['id'].replace({'(.*)(psi_ifmp\\S*)(.*)': '\\\\2'},\n",
    "                                              regex = True)\n",
    "projects_df = pd.merge(projects_df, researchers_df, how = 'left', on = 'id')\n",
    "# Filter by researchers from IFMP and save to Excel.\n",
    "projects_df = projects_df[projects_df['id'].str.contains('psi', na = False)]\n",
    "projects_df = projects_df.reset_index(drop = True)\n",
    "projects_df.to_excel('investigacion.xlsx')\n",
    "# Filter by most recent (and probably ongoing) research projects only.\n",
    "flter = (\n",
    "    ((projects_df['fecha fin'] > '2022-01-01') | \n",
    "    (projects_df['fecha fin'].isna())) &\n",
    "    (projects_df['anio'] > 2017) & \n",
    "    ((projects_df['area anii'] == 'investigacion') |\n",
    "    projects_df['area anii'].isna()) &\n",
    "    (projects_df['convocatoria'] != 'becas posgrado')\n",
    ")\n",
    "research_df = projects_df[flter].reset_index(drop = True)\n",
    "research_df.to_excel('proyectos.xlsx')\n",
    "\n",
    "############################# SNI MERGING #####################################\n",
    "# \"Merge\" that identifies researchers from IFyMP in SNI (assigning an ID).\n",
    "sni_df['id'] = sni_df['nombre completo'].replace(to_repl, vals, regex = True)\n",
    "sni_df['id'] = sni_df['id'].replace({'(.*)(psi_ifmp\\S*)(.*)': '\\\\2'}, \n",
    "                                    regex = True)\n",
    "sni_df = pd.merge(sni_df, researchers_df, how = 'left', on = 'id')\n",
    "# Filter by IFyMP researchers, then export to Excel.\n",
    "ifmp_sni_df = sni_df[sni_df['id'].str.contains('psi', na = False)]\n",
    "ifmp_sni_df = ifmp_sni_df.reset_index(drop = True)\n",
    "ifmp_sni_df.to_excel('sni_ifmp.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
