{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3457ea62-4589-475f-90d2-54d9286a3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is the data cleaner program.\n",
    "\n",
    "This program (created to run in notebooks), transforms (cleans and normalizes)\n",
    "the outputs from web_scrapper.ipynb. It also matches the data with researchers\n",
    "from IFMP, thus it relies on that data being up to date.\n",
    "\n",
    "Created on Sun Aug  1 10:43:34 2021\n",
    "\"\"\"\n",
    "\n",
    "__version__ = '0.5'\n",
    "__author__ = 'Juan Ignacio Rodríguez Vinçon'\n",
    "\n",
    "############################ IMPORT LIBRARIES ################################\n",
    "import unicodedata\n",
    "import json\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41cf3b9-2f7b-451e-9feb-669866bd6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anii.json has different length for each attribute. Before making it a\n",
    "# Data Frame it needs to have the same length.\n",
    "with open(r'data_cleaner_inputs\\jsons\\anii.json', 'r') as fp:\n",
    "    anii_dict = json.load(fp)\n",
    "anii_dict['anio'].extend('n/a')\n",
    "\n",
    "# Load the data and create a Data Frame from it:\n",
    "anii = pd.DataFrame(anii_dict)\n",
    "csic = pd.read_json(r'data_cleaner_inputs\\jsons\\csic.json')\n",
    "ei = pd.read_json(r'data_cleaner_inputs\\jsons\\ei.json')\n",
    "sni = pd.read_json(r'data_cleaner_inputs\\jsons\\sni.json')\n",
    "\n",
    "# Open manually compiled data and data with researchers' names (includes alts.)\n",
    "manual_df = pd.read_excel(r'data_cleaner_inputs\\manually_retrieved_data.xlsx',\n",
    "                          na_values = 'n/a')\n",
    "researchers_df = pd.read_excel(r'data_cleaner_inputs\\ifmp_researchers.xlsx',\n",
    "                               na_values = 'n/a')\n",
    "\n",
    "############################# ANII DATAFRAME ##################################\n",
    "# Identify missing values.\n",
    "anii = anii.replace('n/a', np.nan)\n",
    "# Get the correct year for each project.\n",
    "anii['anio'] = anii['codigo'].replace({'(.*)((?<=\\_)\\d{4}(?=\\_))(.*)': '\\\\2'},\n",
    "                                      regex = True)\n",
    "\n",
    "# The column \"beneficiario\" has both the institution and the name of the\n",
    "# reponsible person for the project. Thus that information must be separated.\n",
    "anii['institucion'] = (\n",
    "    anii['beneficiario'].replace(r'^.*\\:', '', regex = True).str.strip()\n",
    "    )\n",
    "anii['beneficiario'] = (\n",
    "    anii['beneficiario'].replace(r'\\:.*$', '', regex = True).str.strip()\n",
    "    )\n",
    "anii = anii.replace(r'^\\s*$', np.nan, regex = True)\n",
    "\n",
    "# Calculate the finishing date for each project:\n",
    "# Replace non date values with missing values.\n",
    "anii['fecha de inicio'] = (\n",
    "    anii['fecha de inicio'].replace('00.00.0000', np.nan)\n",
    "    )\n",
    "# Convert 'fecha de inicio' to datetime format\n",
    "anii['fecha de inicio'] = (\n",
    "    pd.to_datetime(anii['fecha de inicio'], format = '%d.%m.%Y')\n",
    "    )\n",
    "# Assign a variable to store the data in 'duracion' as integers\n",
    "anii['offset'] = (\n",
    "    pd.to_numeric(\n",
    "        anii['duracion'].replace(r'\\s\\w*$', '', regex = True).str.strip(),\n",
    "        errors = 'coerce'\n",
    "        ).fillna(0).astype('Int8')\n",
    "    )\n",
    "# Create 'fecha fin' column that adds 'fecha de inicio' and 'offset'\n",
    "anii['fecha fin'] = (\n",
    "    anii.apply(\n",
    "        lambda x: x['fecha de inicio'] + pd.DateOffset(months = x['offset']),\n",
    "        axis = 1\n",
    "        )\n",
    "    )\n",
    "anii = anii.drop(columns = 'offset')\n",
    "# Clean the 'responsable' column of multiple whitespaces.\n",
    "anii['beneficiario'] = (\n",
    "    anii['beneficiario'].str.replace(' +', ' ', regex = False)\n",
    "    )\n",
    "anii['beneficiario'] = anii['beneficiario'].str.split(',')\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "anii['anio'] = anii['anio'].astype('float').astype('Int32')\n",
    "\n",
    "############################# SNI DATAFRAME ##################################\n",
    "# Identify missing values.\n",
    "sni = sni.replace('n/a', np.nan)\n",
    "# The 'name' columns is in \"Last Name , First Name\" format. In order to join\n",
    "# the datasets it should be in First Name Last Name (or Full Name) format.\n",
    "sni['nombres'] = (\n",
    "    sni['nombre'].replace(r'^.*\\,', '', regex = True).str.strip() # limpiar con unicode data (tildes)\n",
    "    )\n",
    "sni['nombres'] = sni['nombres'].str.replace(' +', ' ', regex = False)\n",
    "sni['apellidos'] = (\n",
    "    sni['nombre'].replace(r'\\,.*$', '', regex = True).str.strip()\n",
    "    )\n",
    "sni['apellidos'] = sni['apellidos'].str.replace(' +', ' ', regex = False)\n",
    "sni['nombre'] = sni['nombres'] + ' ' + sni['apellidos']\n",
    "\n",
    "############################## EI DATAFRAME ###################################\n",
    "# Identify missing values.\n",
    "ei = ei.replace('n/a', np.nan)\n",
    "# Create 'fecha de inicio' and 'fecha fin' from 'periodo'. Then convert them\n",
    "# to datetime format.\n",
    "ei['periodo'] = ei['periodo'].replace(r'\\n', '', regex = True)\n",
    "ei['fecha de inicio'] = (\n",
    "    ei['periodo'].replace(r'\\-\\s.*$', '', regex = True).str.strip()\n",
    "    )\n",
    "ei['fecha fin'] = (\n",
    "    ei['periodo'].replace(r'^.*\\s\\-', '', regex = True).str.strip()\n",
    "    )\n",
    "ei['fecha de inicio'] = (\n",
    "    pd.to_datetime(ei['fecha de inicio'], format = '%Y-%m-%d')\n",
    "    )\n",
    "ei['fecha fin'] = pd.to_datetime(ei['fecha fin'], format = '%Y-%m-%d')\n",
    "# Extract year from 'convocatoria' and thus create the column 'anio'.\n",
    "ei['anio'] = (\n",
    "    ei['convocatoria'].replace(r'^\\D*|\\s\\(.*\\)$|\\s\\-\\s.*$',\n",
    "                               '', regex = True).str.strip()\n",
    "    )\n",
    "# Clean 'convocatoria' from having each row start with the word 'convocatoria'\n",
    "# (thus avoiding redundancy).\n",
    "ei['convocatoria'] = (\n",
    "    ei['convocatoria']\n",
    "    .replace(r'^convocatoria\\s\\-\\s|^convocatoria\\sal|^convocatoria\\s',\n",
    "             '', regex = True).str.strip()\n",
    "    )\n",
    "# Create column 'enlace' to contain, as a list, 'url_grupo' and 'url_convo'.\n",
    "ei['enlace'] = ei[['url_grupo', 'url_convo']].values.tolist()\n",
    "# If dataset was opened (and not in working memory) it may be necessary to\n",
    "# convert 'responsables' to list (from string) for later use in .explode\n",
    "#isna = ei_df['responsables'].isna()\n",
    "#ei_df.loc[isna, 'responsables'] = pd.Series([[]] * isna.sum()).values\n",
    "#ei['responsables'] = ei['responsables'].fillna('[]')\n",
    "#ei['responsables'] = ei['responsables'].apply(literal_eval)\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "ei['anio'] = ei['anio'].astype('float').astype('Int32')\n",
    "# Correct mistakes in some values (e.g.: \"vazquez\" should be \"vasquez\").\n",
    "to_repl = (\n",
    "    ei[ei['grupo'].str.contains('cicea', na = False)].index.to_list()\n",
    "    )\n",
    "for i in range(len(to_repl)):\n",
    "    ei['responsables'].iloc[to_repl[i]].remove('alejandro vazquez')\n",
    "    ei['responsables'].iloc[to_repl[i]].extend(['alejandro vasquez'])\n",
    "\n",
    "to_repl = (\n",
    "    ei[ei['grupo'].str.contains('cicada', na = False)].index.to_list()\n",
    "    )\n",
    "ei['responsables'].iloc[to_repl[0]].extend(['alvaro cabana fajardo'])\n",
    "\n",
    "############################ CSIC DATAFRAME ###################################\n",
    "# Identify missing values.\n",
    "csic = csic.replace('n/a', np.nan)\n",
    "# If dataset was opened (and not in working memory) it may be necessary to\n",
    "# convert 'responsables' to list (from string) for later use in .explode\n",
    "#isna = csic_df['responsables'].isna()\n",
    "#csic_df.loc[isna, 'responsables'] = pd.Series([[]] * isna.sum()).values\n",
    "#csic['responsables'] = csic['responsables'].fillna('[]')\n",
    "#csic['responsables'] = csic['responsables'].apply(literal_eval)\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "csic['ano'] = csic['ano'].astype('float').astype('Int32')\n",
    "\n",
    "############################ MANUAL DATAFRAME #################################\n",
    "manual_df['responsables'] = manual_df['responsables'].apply(literal_eval)\n",
    "# Change dtype for 'anio' to integer (Int32).\n",
    "manual_df['anio'] = manual_df['anio'].astype('float').astype('Int32')\n",
    "\n",
    "############################ RESEARCHERS DF ###################################\n",
    "# Normalize data in the columns.\n",
    "for col in researchers_df.columns[:-2]:\n",
    "    researchers_df[col] = (researchers_df[col]\n",
    "                           .str.lower()\n",
    "                           .str.normalize('NFKD')\n",
    "                           .str.encode('ascii', 'ignore')\n",
    "                           .str.decode('utf8')\n",
    "                           .str.strip())\n",
    "\n",
    "# Replace common names, that can be matched erronously, with NaN.\n",
    "to_repl = ['diego gonzalez', # antes estaba \"gonzalez garcia\"\n",
    "           'cecilia gomez', # problema empty string, debería estar solucionado\n",
    "           'ignacio rodriguez', # antes estaba \"monica da silva\"\n",
    "           'nicolas lopez', # empty string, debería estar solucionado\n",
    "           'monica perez',\n",
    "           'juan rodriguez',\n",
    "           'sebastian morales',\n",
    "           'daniel perez'] # agregado \"daniel perez\", situación empty string\n",
    "researchers_df = researchers_df.replace(to_repl, np.nan)\n",
    "\n",
    "# Create a Regex list out of the columns in 'cols' in order to have matches\n",
    "# when merging dataframes. This will account for name variations, for example,\n",
    "# it would match 'alejandro maiche' and 'alejandro maiche marini'.\n",
    "cols = [c for c in researchers_df.columns[5:-2]]\n",
    "researchers_df = researchers_df.fillna('')\n",
    "to_repl = []\n",
    "for idx, row in researchers_df[cols].iterrows():\n",
    "    tmp = row.to_list()\n",
    "    tmp[:] = [x for x in tmp if x]\n",
    "    to_repl.append('|'.join(tmp))\n",
    "# Create a new column with the Regex, replace the empty strings with NaN and\n",
    "# clean the DF of NaN (those that don't have any name variation, e.g.: 'cecilia\n",
    "# gomez'). Thus avoiding matching with empty strings when \"merging\".\n",
    "researchers_df['regex'] = to_repl\n",
    "researchers_df = researchers_df.replace('', np.nan)\n",
    "researchers_df = researchers_df.dropna(how = 'all', subset = cols)\n",
    "to_repl = researchers_df['regex'].to_list()\n",
    "vals = researchers_df['id'].to_list()\n",
    "# Drop columns that are not needed in the merge\n",
    "cols.extend(['grado', 'primer nombre', 'segundo nombre',\n",
    "            'primer apellido', 'segundo apellido', 'regex'])\n",
    "researchers_df = researchers_df.drop(columns = cols)\n",
    "\n",
    "########################## REARRANGING COLUMNS ################################\n",
    "# Rename and rearrange columns order.\n",
    "anii = anii.rename(\n",
    "    columns = {'beneficiario': 'responsables',\n",
    "               'instrumento': 'convocatoria',\n",
    "               'codigo': 'id',\n",
    "               'fase_estado': 'fase estado anii',\n",
    "               'subsidio': 'monto',\n",
    "               'proyecto': 'nombre de proyecto / grupo',\n",
    "               'institucion': 'instituciones',\n",
    "               'area': 'area anii',\n",
    "               'sector': 'area'}\n",
    "    )\n",
    "cols = ['id', 'responsables', 'instituciones', 'convocatoria', 'anio',\n",
    "        'fecha de inicio', 'fecha fin', 'duracion', 'area', 'monto']\n",
    "anii = anii[cols + [c for c in anii.columns if c not in cols]]\n",
    "\n",
    "csic = csic.rename(\n",
    "    columns = {'ano': 'anio',\n",
    "               'monto total': 'monto',\n",
    "               'proyecto': 'nombre de proyecto / grupo',\n",
    "               'programa': 'convocatoria',\n",
    "               'area proyecto': 'area'}\n",
    "    )\n",
    "cols = ['responsables', 'convocatoria', 'anio', 'monto']\n",
    "csic = csic[cols + [c for c in csic.columns if c not in cols]]\n",
    "\n",
    "ei = ei.rename(\n",
    "    columns = {'servicios involucrados': 'instituciones',\n",
    "               'grupo': 'nombre de proyecto / grupo'}\n",
    "    )\n",
    "cols = ['responsables', 'instituciones', 'convocatoria', 'anio',\n",
    "        'fecha de inicio', 'fecha fin', 'periodo']\n",
    "ei = ei[cols + [c for c in ei.columns if c not in cols]]\n",
    "\n",
    "sni = sni.rename(columns = {'nombre': 'nombre completo'})\n",
    "cols = ['nombre completo', 'nombres', 'apellidos', 'nivel']\n",
    "sni = sni[cols + [c for c in sni.columns if c not in cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34c49c3-6298-40a2-b82a-af402c539bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## PROJECTS MERGING ################################\n",
    "# Add a column to identify the founding party once the DFs are joined\n",
    "anii['institucion financiadora'] = 'anii'\n",
    "csic['institucion financiadora'] = 'csic'\n",
    "ei['institucion financiadora'] = 'ei'\n",
    "for col in ['fase estado anii', 'area anii']:\n",
    "    ei[col] = np.nan\n",
    "    csic[col] = np.nan\n",
    "\n",
    "cols =  ['responsables',\n",
    "         'instituciones',\n",
    "         'institucion financiadora',\n",
    "         'convocatoria',\n",
    "         'anio',\n",
    "         'fecha de inicio',\n",
    "         'fecha fin',\n",
    "         'area',\n",
    "         'monto',\n",
    "         'nombre de proyecto / grupo',\n",
    "         'enlace',\n",
    "         'fase estado anii',\n",
    "         'area anii'] # agregar id anii? y dpto anii?\n",
    "\n",
    "# Drop columns that will not be used in joined DF.\n",
    "for df in [anii, csic, ei]:\n",
    "    df.drop(columns = [c for c in df.columns if c not in cols], inplace = True)\n",
    "# Concat DFs, one with all the projects, another with research only projects.\n",
    "projects_df  = pd.DataFrame(columns = cols)\n",
    "#research_df = pd.DataFrame(columns = cols)\n",
    "projects_df = pd.concat([anii, csic, ei, manual_df], ignore_index = True)\n",
    "#research_df = pd.concat([anii_df[anii_df['area anii'] == 'investigacion'],\n",
    " #                        csic_df, ei_df, manual_df], ignore_index = True)\n",
    "\n",
    "# Final \"merge\" that identifies researchers from IFyMP and assigns them an ID. <<<<<<<<<<<<<<<<<<<<< revisar\n",
    "projects_df = (\n",
    "    projects_df[projects_df['responsables'].notna()]\n",
    "    .explode('responsables', True)\n",
    "    )\n",
    "projects_df['id'] = projects_df['responsables'].replace(to_repl, vals,\n",
    "                                                        regex = True)\n",
    "projects_df['id'] = projects_df['id'].replace({'(.*)(psi_ifmp\\S*)(.*)': '\\\\2'},\n",
    "                                              regex = True)\n",
    "projects_df = pd.merge(projects_df, researchers_df, how = 'left', on = 'id')\n",
    "# Filter by researchers from IFMP and save to Excel.\n",
    "projects_df = projects_df[projects_df['id'].str.contains('psi', na = False)]\n",
    "projects_df = projects_df.reset_index(drop = True)\n",
    "projects_df.to_csv(r'datasets\\research_projects_dataset.csv')\n",
    "# Filter by most recent (and probably ongoing) research projects only.\n",
    "flter = (\n",
    "    ((projects_df['fecha fin'] > '2022-01-01') |\n",
    "    (projects_df['fecha fin'].isna())) &\n",
    "    (projects_df['anio'] > 2017) &\n",
    "    ((projects_df['area anii'] == 'investigacion') |\n",
    "    projects_df['area anii'].isna()) &\n",
    "    (projects_df['convocatoria'] != 'becas posgrado')\n",
    "    )\n",
    "research_df = projects_df[flter].reset_index(drop = True)\n",
    "research_df.to_csv(r'datasets\\ifmp_research_projects.csv')\n",
    "\n",
    "############################# SNI MERGING #####################################\n",
    "# \"Merge\" that identifies researchers from IFyMP in SNI (assigning an ID).\n",
    "sni['id'] = sni['nombre completo'].replace(to_repl, vals, regex = True)\n",
    "sni['id'] = sni['id'].replace({'(.*)(psi_ifmp\\S*)(.*)': '\\\\2'},\n",
    "                              regex = True)\n",
    "sni = pd.merge(sni, researchers_df, how = 'left', on = 'id')\n",
    "# Filter by IFyMP researchers, then export to Excel.\n",
    "ifmp_sni_df = sni[sni['id'].str.contains('psi', na = False)]\n",
    "ifmp_sni_df = ifmp_sni_df.reset_index(drop = True)\n",
    "ifmp_sni_df.to_csv(r'datasets\\sni_ifmp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
